{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Predictor .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkcK66OfS4jzD9wtoouYna",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sankalp-Bisht/Language-classifier/blob/master/Language_Predictor_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWEsei3JnATZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as mpl \n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import joblib\n",
        "import pickle as pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrKPna0Qo6V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def open_file(filename):\n",
        "  with open(filename ,r) as f:\n",
        "    data=f.readlines()\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb0Lnntvpc8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_raw = dict()\n",
        "data_raw[\"English\"] = open(r\"English2.txt\").readlines()\n",
        "data_raw[\"Spanish\"] = open(r\"Spanish2.txt\").readlines()\n",
        "data_raw[\"French\"] = open(r\"french2.txt\").readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjMC9B2HqOEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showstats(lang):\n",
        "  for language, sentences in lang.items():\n",
        "\n",
        "    number_of_sentences=0\n",
        "    number_of_words=0\n",
        "    number_of_unique_words=0\n",
        "    sample_extract= ''\n",
        "\n",
        "    word_list = ' '.join(sentences).split()\n",
        "        \n",
        "    number_of_sentences=len(sentences)\n",
        "    number_of_words=len(word_list)\n",
        "    number_of_unique_world= len(set(word_list))\n",
        "    sample_extract=' '.join(sentences[0].split()[0:7])\n",
        "    word_list = ' '.join(sentences).split()\n",
        "\n",
        "    word_list = ' '.join(sentences).split()\n",
        "    print(f'Language: {language}')\n",
        "    print('-----------------------')\n",
        "    print(f'Number of sentences\\t:\\t {number_of_sentences}')\n",
        "    print(f'Number of words\\t\\t:\\t {number_of_words}')\n",
        "    print(f'Number of unique words\\t:\\t {number_of_unique_words}')\n",
        "    print(f'Sample extract\\t\\t:\\t {sample_extract}...\\n')\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esTVLjuvq1mB",
        "colab_type": "code",
        "outputId": "b0f5fedc-f857-4c0a-b574-300570be40c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "showstats(data_raw)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Language: English\n",
            "-----------------------\n",
            "Number of sentences\t:\t 401\n",
            "Number of words\t\t:\t 11333\n",
            "Number of unique words\t:\t 0\n",
            "Sample extract\t\t:\t The English Wikipedia is the English-language edition...\n",
            "\n",
            "Language: Spanish\n",
            "-----------------------\n",
            "Number of sentences\t:\t 498\n",
            "Number of words\t\t:\t 9644\n",
            "Number of unique words\t:\t 0\n",
            "Sample extract\t\t:\t El príncipe Alberto Víctor, duque de Clarence...\n",
            "\n",
            "Language: French\n",
            "-----------------------\n",
            "Number of sentences\t:\t 200\n",
            "Number of words\t\t:\t 6402\n",
            "Number of unique words\t:\t 0\n",
            "Sample extract\t\t:\t Hilda Rix Nicholas, née le 1er septembre...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8GI7pvh5Gcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    preprocessed_text = text.lower().replace('-', ' ')\n",
        "    \n",
        "    translation_table = str.maketrans('\\n', ' ', string.punctuation + string.digits)\n",
        "    \n",
        "    preprocessed_text = preprocessed_text.translate(translation_table)\n",
        "        \n",
        "    return preprocessed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHkBs5mF6_3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_preprocessed = {k: [preprocess(sentences) for sentences in v] for k , v in data_raw.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMiZkICL7ePd",
        "colab_type": "code",
        "outputId": "672a0fcc-e7e9-462f-ba93-f1faaed87056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "showstats(data_preprocessed)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Language: English\n",
            "-----------------------\n",
            "Number of sentences\t:\t 401\n",
            "Number of words\t\t:\t 10807\n",
            "Number of unique words\t:\t 0\n",
            "Sample extract\t\t:\t the english wikipedia is the english language...\n",
            "\n",
            "Language: Spanish\n",
            "-----------------------\n",
            "Number of sentences\t:\t 498\n",
            "Number of words\t\t:\t 9454\n",
            "Number of unique words\t:\t 0\n",
            "Sample extract\t\t:\t el príncipe alberto víctor duque de clarence...\n",
            "\n",
            "Language: French\n",
            "-----------------------\n",
            "Number of sentences\t:\t 200\n",
            "Number of words\t\t:\t 6065\n",
            "Number of unique words\t:\t 0\n",
            "Sample extract\t\t:\t hilda rix nicholas née le er septembre...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4vffe1R7jGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_train , y_train = [], []\n",
        "\n",
        "for k, v in data_preprocessed.items():\n",
        "  for sentences in v:\n",
        "    sentences_train.append(sentences)\n",
        "    y_train.append(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6sC2GcT8NnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQyeKRSG8NqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = vectorizer.fit_transform(sentences_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm3HuKdl8Nto",
        "colab_type": "code",
        "outputId": "16dcd841-1fbd-4161-ebba-d0d69043db33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NC = MultinomialNB(alpha=0.01, fit_prior=True)\n",
        "NC.fit(X_train, y_train)\n"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYPTIApB8NlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_val = dict()\n",
        "data_val['Spanish'] = open(r\"Spanishtest.txt\").readlines()\n",
        "data_val['French'] = open(r\"Frenchtest.txt\").readlines()\n",
        "data_val['English'] = open(r\"Englishtest.txt\").readlines()\n",
        "\n",
        "data_val_preprocessed = {k: [preprocess(sentence) for sentence in v] for k, v in data_val.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYY-Sw_9-YaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_val, y_val = [], []\n",
        "\n",
        "for k, v in data_val_preprocessed.items():\n",
        "    for sentence in v:\n",
        "        sentences_val.append(sentence)\n",
        "        y_val.append(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6pwz79V-eg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = vectorizer.transform(sentences_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpH38jbI-fWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = NC.predict(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c7oJgCk-ncj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f667d7e-f26d-4a44-e021-0fd313c022b9"
      },
      "source": [
        "f1_score(y_val, predictions, average='weighted')"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8993366420397274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJjTYNViaIpT",
        "colab_type": "text"
      },
      "source": [
        "**Testing the model against few sentences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0_tLjarWc48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e6e093a-8019-4a30-8fa6-29c03f316d3d"
      },
      "source": [
        "sentence_1 = \"Thankyou for visiting the project\"\n",
        "sentence_1 = [preprocess(sentence_1)]\n",
        "text_vectorized = vectorizer.transform(sentence_1)\n",
        "Predict = NC.predict(text_vectorized)\n",
        "Predict[0]"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'English'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmDIIWsQc46J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38e6a861-cab5-4592-a70e-4d2ef92cf1eb"
      },
      "source": [
        "sentence_2 = \"Gracias por visitar el proyecto\"\n",
        "sentence_2 = [preprocess(sentence_2)]\n",
        "text_vectorized = vectorizer.transform(sentence_2)\n",
        "Predict = NC.predict(text_vectorized)\n",
        "Predict[0]"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Spanish'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSWW4ZBBd7Jf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81845448-f34d-4b09-a40f-a09cc3a488e3"
      },
      "source": [
        "sentence_3 = \"Merci d'avoir visité le projet\"\n",
        "sentence_3 = [preprocess(sentence_3)]\n",
        "text_vectorized = vectorizer.transform(sentence_3)\n",
        "Predict = NC.predict(text_vectorized)\n",
        "Predict[0]"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'French'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    }
  ]
}